# Reddit Job Post Scraper & Analyzer

Automated pipeline for scraping job posts from Reddit and analyzing them with AI to extract structured data, plus a web interface to browse and search jobs.

## Features

- ğŸ¤– **Automated Scraping**: Scheduled scraper runs every 2 hours via cron
- ğŸ’¾ **PostgreSQL Storage**: Stores both raw and processed job post data
- ğŸ”„ **Async Processing**: RabbitMQ queue for decoupled LLM processing
- ğŸ§  **AI Analysis**: Uses Llama 3.1 via Ollama (free, self-hosted) to extract:
  - Cleaned title and description
  - Job tags (type, level, technologies, location, etc.)
- ğŸŒ **Web Frontend**: Next.js app to browse, search, and filter jobs
- ğŸ“Š **REST API**: FastAPI backend with filtering and pagination
- ğŸ³ **Fully Dockerized**: One command to run everything
- âš¡ **GPU Support**: Optional GPU acceleration for 3-5x faster processing

## Architecture

```
Reddit Scraper (Cron)
    â†“
PostgreSQL Database â†â†’ FastAPI (REST API) â†â†’ Next.js Frontend
    â†“                      â†“
RabbitMQ Queue         Port 8000           Port 3000
    â†“
LLM Consumer (Ollama + Llama 3.1)
    â†“
Updated Database with Cleaned Data
```

## Quick Start

1. **Prerequisites:**
   - Docker & Docker Compose
   - Reddit API credentials ([get them here](https://www.reddit.com/prefs/apps))

2. **Configure:**
   ```bash
   # Reddit scraper config
   cp reddit_scraper/.env.template reddit_scraper/.env
   # Edit and add your Reddit API credentials

   # LLM service config (defaults are fine)
   cp llm_service/.env.template llm_service/.env
   ```

3. **Run:**
   ```bash
   docker compose build
   docker compose up -d
   ```

4. **Monitor:**
   ```bash
   docker compose logs -f
   ```

That's it! The system will:
- Scrape Reddit every 2 hours
- Store raw data in PostgreSQL
- Process with LLM (downloads model on first run, ~5 min)
- Update database with cleaned data

## Web Interface

After starting the services, access:
- **Frontend**: http://localhost:3000 - Browse and search jobs
- **API Docs**: http://localhost:8000/docs - Interactive API documentation
- **RabbitMQ UI**: http://localhost:15672 - Queue management (guest/guest)

## Documentation

- **[FRONTEND_SETUP.md](FRONTEND_SETUP.md)** - Frontend setup and development guide
- **[DOCKER_FRONTEND.md](DOCKER_FRONTEND.md)** - Frontend Docker configuration
- **[DOCKER_SETUP.md](DOCKER_SETUP.md)** - Complete Docker setup guide, commands, troubleshooting
- **[GPU_SETUP.md](GPU_SETUP.md)** - Optional GPU acceleration setup for faster processing

## Project Structure

```
reddit-job-posts-web-scraping/
â”œâ”€â”€ frontend/               # Next.js web interface
â”‚   â”œâ”€â”€ app/               # Pages and routes
â”‚   â”œâ”€â”€ components/        # React components
â”‚   â”œâ”€â”€ lib/               # API client & types
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ .env.local
â”œâ”€â”€ api/                   # FastAPI backend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ main.py       # API routes
â”‚   â”‚   â”œâ”€â”€ models.py     # Database models
â”‚   â”‚   â””â”€â”€ schemas.py    # API schemas
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ .env
â”œâ”€â”€ reddit_scraper/        # Scraper service
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ scraper.py    # Main scraper logic
â”‚   â”‚   â”œâ”€â”€ db/           # Database models
â”‚   â”‚   â””â”€â”€ messaging/    # RabbitMQ publisher
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ .env.template
â”œâ”€â”€ llm_service/          # LLM analyzer service
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ consumer.py   # RabbitMQ consumer
â”‚   â”‚   â”œâ”€â”€ analyzer.py   # Ollama LLM integration
â”‚   â”‚   â””â”€â”€ database.py   # PostgreSQL client
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ .env.template
â”œâ”€â”€ cron/                 # Cron schedule config
â”œâ”€â”€ docker-compose.yml    # Main orchestration
â””â”€â”€ docker-compose.gpu.yml # GPU acceleration (optional)
```

## Services

| Service | Port | Description |
|---------|------|-------------|
| Frontend | 3000 | Next.js web interface |
| API | 8000 | FastAPI REST backend |
| PostgreSQL | 5432 | Stores job post data |
| RabbitMQ | 5672 | Message queue |
| RabbitMQ UI | 15672 | Management interface |
| Scraper | - | Cron job (every 2h) |
| LLM Consumer | - | Background processor |

## Database Schema

**Table:** `raw_job_posts`

| Column | Type | Description |
|--------|------|-------------|
| `id` | INTEGER | Primary key |
| `reddit_id` | VARCHAR | Unique Reddit post ID |
| `title` | TEXT | Original title |
| `body` | TEXT | Original post body |
| `author` | VARCHAR | Reddit username |
| `created_utc` | TIMESTAMP | Post creation time |
| `score` | INTEGER | Reddit score |
| `url` | TEXT | Post URL |
| `subreddit` | VARCHAR | Source subreddit |
| `scraped_at` | TIMESTAMP | When scraped |
| `cleaned_title` | TEXT | AI-processed title |
| `cleaned_text` | TEXT | AI-processed summary |
| `tags` | JSON | Extracted tags/categories |
| `processed_at` | TIMESTAMP | When processed by LLM |

## Usage Examples

**View unprocessed jobs:**
```bash
docker compose exec postgres psql -U reddit_user -d reddit_jobs -c \
  "SELECT id, title FROM raw_job_posts WHERE processed_at IS NULL;"
```

**View processed jobs with tags:**
```bash
docker compose exec postgres psql -U reddit_user -d reddit_jobs -c \
  "SELECT id, cleaned_title, tags FROM raw_job_posts WHERE processed_at IS NOT NULL LIMIT 5;"
```

**Check processing stats:**
```bash
docker compose exec postgres psql -U reddit_user -d reddit_jobs -c \
  "SELECT
    COUNT(*) FILTER (WHERE processed_at IS NULL) as unprocessed,
    COUNT(*) FILTER (WHERE processed_at IS NOT NULL) as processed
   FROM raw_job_posts;"
```

**RabbitMQ Management UI:**
- Open http://localhost:15672
- Login: `guest` / `guest`
- View queue status and consumer activity

## Performance

| Mode | Speed per Post | Recommended For |
|------|---------------|-----------------|
| CPU | 2-3 seconds | ~100-200 posts/day |
| GPU | 0.5-1 second | 500+ posts/day |

## Technologies

- **Python 3.11**
- **PostgreSQL 16** - Database
- **RabbitMQ 3.12** - Message queue
- **Ollama** - LLM inference engine
- **Llama 3.1 8B** - Language model
- **Docker** - Containerization
- **PRAW** - Reddit API wrapper
- **SQLAlchemy** - ORM
- **Pika** - RabbitMQ client

## License

MIT

## Requirements

- Docker & Docker Compose
- Reddit API credentials (free)
- 8GB+ RAM for LLM service
- (Optional) NVIDIA GPU for faster processing